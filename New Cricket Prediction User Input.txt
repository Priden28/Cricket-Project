{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a159a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1190358/188036916.py:10: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_batting = pd.read_csv('clean_batting.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load data\n",
    "df_team = pd.read_csv('clean_team.csv')\n",
    "df_batting = pd.read_csv('clean_batting.csv')\n",
    "df_bowling = pd.read_csv('clean_bowling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa170a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2596dae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Team', 'ScoreDescending', 'Overs', 'RPO', 'Lead', 'Inns', 'Result',\n",
      "       'Opposition', 'Ground', 'Start Date', 'Declared', 'Wickets', 'Match ID',\n",
      "       'NumericMatchID', 'Host', 'Outcome'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the columns of the dataframe\n",
    "print(df_team.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e509bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dropout\n",
      ".........vars\n",
      "......dropout_1\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "metadata.json                                  2024-07-13 03:06:18           64\n",
      "config.json                                    2024-07-13 03:06:18         2564\n",
      "variables.h5                                   2024-07-13 03:06:18       332432\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'model' is your trained RandomForestClassifier\n",
    "model_filename = 'cricket_match_prediction_model.pkl'\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(model,  open(model_filename, 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa4d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "\n",
    "# Filter data from 1985 onwards\n",
    "df_team = df_team[df_team['Start Date'] >= '1985-01-01']\n",
    "df_batting = df_batting[df_batting['Start Date'] >= '1985-01-01']\n",
    "df_bowling = df_bowling[df_bowling['Start Date'] >= '1985-01-01']\n",
    "\n",
    "# Create Match ID\n",
    "class MatchIDGenerator:\n",
    "    def __init__(self):\n",
    "        self.match_id_dict = {}\n",
    "    \n",
    "    def generate_match_id(self, row):\n",
    "        match_info = f\"{row['Ground']}_{row['Start Date']}\"\n",
    "        match_id = hashlib.sha256(match_info.encode()).hexdigest()\n",
    "        self.match_id_dict[match_id] = (row['Ground'], row['Start Date'])\n",
    "        return match_id\n",
    "\n",
    "match_id_generator = MatchIDGenerator()\n",
    "df_team['Match ID'] = df_team.apply(match_id_generator.generate_match_id, axis=1)\n",
    "df_batting['Match ID'] = df_batting.apply(match_id_generator.generate_match_id, axis=1)\n",
    "df_bowling['Match ID'] = df_bowling.apply(match_id_generator.generate_match_id, axis=1)\n",
    "\n",
    "# Label encoding Match ID\n",
    "all_match_ids = pd.concat([df_team['Match ID'], df_batting['Match ID'], df_bowling['Match ID']], axis=0)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_match_ids)\n",
    "\n",
    "df_team['NumericMatchID'] = label_encoder.transform(df_team['Match ID'])\n",
    "df_batting['NumericMatchID'] = label_encoder.transform(df_batting['Match ID'])\n",
    "df_bowling['NumericMatchID'] = label_encoder.transform(df_bowling['Match ID'])\n",
    "\n",
    "# Count the number of matches hosted by each team at each ground\n",
    "ground_teams_count = {}\n",
    "for ground, group in df_team.groupby('Ground'):\n",
    "    ground_teams_count[ground] = Counter(group['Team'])\n",
    "\n",
    "# Extract year from Start Date\n",
    "df_team['Start Date'] = pd.to_datetime(df_team['Start Date'])\n",
    "df_team['Year'] = df_team['Start Date'].dt.year\n",
    "\n",
    "df_team['Host'] = df_team['Ground'].apply(lambda ground: ground_teams_count[ground].most_common(1)[0][0] if ground in ground_teams_count else '')\n",
    "df_team['Outcome'] = df_team['Result'].map({'won': 1, 'lost': 0, 'draw': 2})\n",
    "\n",
    "print(f\"Number of NaN values in 'Outcome': {df_team['Outcome'].isna().sum()}\")\n",
    "\n",
    "# Drop rows with NaN values in 'Outcome'\n",
    "df_team = df_team.dropna(subset=['Outcome'])\n",
    "\n",
    "features = df_team[['Host', 'Opposition', 'Ground', 'Year']]\n",
    "target = df_team['Outcome']\n",
    "\n",
    "# Encode categorical variables\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ece4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Team 1 name: West Indies\n",
      "Enter Team 2 name: Australia\n",
      "Enter ground name: Colombo\n",
      "Enter start date (YYYY-MM-DD): 2006-08-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted win percentage for West Indies: 10.00%\n",
      "Predicted draw percentage for West Indies: 13.00%\n",
      "Total predicted percentage for West Indies (win + draw): 23.00%\n",
      "Predicted win percentage for Australia: 48.25%\n",
      "Predicted draw percentage for Australia: 14.00%\n",
      "Total predicted percentage for Australia (win + draw): 62.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n",
      "/tmp/ipykernel_1190358/3165085463.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  input_encoded[col] = 0\n"
     ]
    }
   ],
   "source": [
    "def preprocess_user_input(team1_name, team2_name, ground_name, start_date):\n",
    "    input_data = {\n",
    "        'Host': team1_name,\n",
    "        'Opposition': team2_name,\n",
    "        'Ground': ground_name,\n",
    "        'Year': start_date.year  # Extracting the year from the date\n",
    "    }\n",
    "    \n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    \n",
    "    # Perform one-hot encoding\n",
    "    input_encoded = pd.get_dummies(input_df)\n",
    "    \n",
    "    # Ensure columns match the training data\n",
    "    missing_cols = set(features_encoded.columns) - set(input_encoded.columns)\n",
    "    for col in missing_cols:\n",
    "        input_encoded[col] = 0\n",
    "    \n",
    "    # Reorder columns to match the training data\n",
    "    input_encoded = input_encoded[features_encoded.columns]\n",
    "    \n",
    "    return input_encoded\n",
    "\n",
    "# Function to prompt user for input and return team names, ground, and start date\n",
    "def get_user_input():\n",
    "    team1_name = input(\"Enter Team 1 name: \")\n",
    "    team2_name = input(\"Enter Team 2 name: \")\n",
    "    ground_name = input(\"Enter ground name: \")\n",
    "    start_date_input = input(\"Enter start date (YYYY-MM-DD): \")\n",
    "    start_date = datetime.datetime.strptime(start_date_input, '%Y-%m-%d')\n",
    "    return team1_name, team2_name, ground_name, start_date\n",
    "\n",
    "# Example usage:\n",
    "def predict_match_outcome():\n",
    "    team1_name, team2_name, ground_name, start_date = get_user_input()\n",
    "    \n",
    "    # Preprocess user input\n",
    "    input_data_team1 = preprocess_user_input(team1_name, team2_name, ground_name, start_date)\n",
    "    input_data_team2 = preprocess_user_input(team2_name, team1_name, ground_name, start_date)\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    predicted_probabilities_team1 = model.predict_proba(input_data_team1)[0]\n",
    "    predicted_probabilities_team2 = model.predict_proba(input_data_team2)[0]\n",
    "    \n",
    "    win_percentage_team1 = predicted_probabilities_team1[1] * 100\n",
    "    draw_percentage_team1 = predicted_probabilities_team1[2] * 100\n",
    "    win_percentage_team2 = predicted_probabilities_team2[1] * 100\n",
    "    draw_percentage_team2 = predicted_probabilities_team2[2] * 100\n",
    "    \n",
    "    total_percentage_team1 = win_percentage_team1 + draw_percentage_team1\n",
    "    total_percentage_team2 = win_percentage_team2 + draw_percentage_team2\n",
    "    \n",
    "    print(f'Predicted win percentage for {team1_name}: {win_percentage_team1:.2f}%')\n",
    "    print(f'Predicted draw percentage for {team1_name}: {draw_percentage_team1:.2f}%')\n",
    "    print(f'Total predicted percentage for {team1_name} (win + draw): {total_percentage_team1:.2f}%')\n",
    "    \n",
    "    print(f'Predicted win percentage for {team2_name}: {win_percentage_team2:.2f}%')\n",
    "    print(f'Predicted draw percentage for {team2_name}: {draw_percentage_team2:.2f}%')\n",
    "    print(f'Total predicted percentage for {team2_name} (win + draw): {total_percentage_team2:.2f}%')\n",
    "\n",
    "# Call the function to predict match outcomes based on user input\n",
    "predict_match_outcome()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1922a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4-TensorFlow-2.11.0-cuda [jupyter_python]",
   "language": "python",
   "name": "sys_python_3.10.4-tensorflow-2.11.0-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
